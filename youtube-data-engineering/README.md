# ğŸ“Š Data Engineering YouTube Analysis Project

**Author**: Abdullah Anwer  
**Live Portfolio**: [abdullahwork.online](https://abdullahwork.online)

## ğŸ” Overview
This project securely manages, transforms, and analyzes YouTube trending video data using AWS services in a scalable, serverless data pipeline.

## ğŸ¯ Project Goals
- **Data Ingestion** from multiple raw sources (CSV, JSON)
- **ETL Process** with Lambda and Glue
- **Centralized Storage** using Amazon S3 as a Data Lake
- **Scalability** using serverless architecture
- **Cloud Deployment** using AWS
- **Reporting & Visualization** using QuickSight

## ğŸ› ï¸ AWS Services Used
- **Amazon S3**: Object storage for raw and transformed data
- **AWS Lambda**: Parses JSON and triggers ETL
- **AWS Glue**: Performs data transformations and quality checks
- **AWS IAM**: Manages secure access
- **Amazon Athena**: SQL querying on S3 data
- **Amazon QuickSight**: Dashboard for insights

## ğŸ“ Dataset
Source: [Kaggle YouTube Trending Data](https://www.kaggle.com/datasets/datasnaek/youtube-new)

## ğŸ§± Architecture Diagram
![Architecture](architecture/architecture.png)

## ğŸ§¬ Lambda Function (JSON Ingestion)
[lambda/lambda_function.py](lambda/lambda_function.py)

## ğŸ§ª AWS Glue Script (ETL + DQ)
[glue_jobs/youtube_glue_job.py](glue_jobs/youtube_glue_job.py)

## ğŸ§¾ CLI Upload Commands
Stored in [aws_cli_commands.md](aws_cli_commands.md)

## ğŸ“Š Reporting
Visual insights were generated using Amazon QuickSight. [Sample PDF](architecture/quicksight_dashboard.pdf)

## ğŸš€ How to Run
1. Upload CSVs to S3 using `aws s3 cp`
2. Trigger Lambda via S3 upload event
3. Glue Job performs transformations
4. Data written to S3 in Parquet format, queryable via Athena
5. Dashboard generation in QuickSight

## ğŸ“¦ Future Improvements
- Automate pipeline using Step Functions
- Integrate real-time streaming data
- Expand dashboard filters & interactivity
